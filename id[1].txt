Slip 1
...............................

import numpy as np
import math
from sklearn.metrics import mean_squared_error , mean_absolute_error

actual = [2, 3, 3, 5, 9]
calculated = [5, 5, 1, 7, 2]

MAE = mean_absolute_error (actual, calculated)
print ("Mean Absolute Error: "+ str (MAE))

MSE = np.square (np.subtract(actual, calculated)).mean()
print ("Mean Squared Error: "+ str (MSE))

RMSE = math.sqrt(MSE)
print ("Root Mean Square Error: "+str (RMSE))

slip 2
...................................

import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs

data = make_blobs (n_samples=300, n_features=2, centers=5, cluster_std=1.8, random_state=101)
data[0].shape
data[1]

from sklearn.cluster import KMeans
kmeans = KMeans (n_clusters=5)
kmeans.fit(data[0])
kmeans.label_f, (ax1, ax2) = plt.subplots (1,2, sharey=True, figsize=(10,6))
ax1.set_title ('Original')
ax1.scatter (data[0][:,0], data[0][:,1], c=data[1], cmap='brg')
ax2.set_title ('K=Means')
ax2.scatter (data[0][:,0], data[0][:,1], c=kmeans.labels_, cmap='brg')
plt.show()


Slip 3
.....................................

import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error , r2_score
import matplotlib.pyplot as plt 

x = np.array([0,1,2,3,4,5,6,7,8,9,11,13]).reshape(-1,1)
y = np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12,16, 18])

model = LinearRegression()

model.fit(x,y)

b0 = model.intercept_
b1 = model.coef_[0]

print("b0 : " , b0 , "\nb1 : " , b1)


Slip 4
..........................................

weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny','Rainy','Sunny','Overcast','Overcast','Rainy']
temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']
play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

w=le.fit_transform(weather)
print ("Weather: ",w)

temp=le.fit_transform(temp)
play=le.fit_transform(play)

print ("\nTemperature: ",temp)
print ("\nPlay: ",play)

features=list(zip(w,temp))
print ("\nWeather,Temp: ",features)

from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
model.fit(features,play)
predicted= model.predict([[0,2]])

print ("\nPredicted Value:", predicted)

Slip 5
.................................................................

import pandas as pd
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score, classification_report

data = pd.read_csv('diabetes.csv')

x = data[['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']]
y = data['Outcome']

x_train , x_test , y_train , y_test = train_test_split(x,y, test_size = 0.2 , random_state = 42)

clf = DecisionTreeClassifier()
clf.fit(x_train,y_train)

y_pred = clf.predict(x_test)

acc_ = accuracy_score(y_test,y_pred)
cr = classification_report(y_test,y_pred)

print("Acc : " , acc_ , "\ncr : " , cr )


Slip 6
.................................................................

import pandas as pd
import matplotlib.pyplot as mtp
df = pd.read_csv ('mallcustomers.csv')
x = df.iloc [:, [3,4]].values

import scipy.cluster.hierarchy as shc
dendro = shc.dendrogram (shc.linkage (x,method='ward'))
mtp.title ("Dendrogram")
mtp.xlabel ("Customer")
mtp.ylabel ("Euclidean distance")
mtp.show()

from sklearn.cluster import AgglomerativeClustering
hc = AgglomerativeClustering (n_clusters=5, affinity='euclidean', linkage='ward')
y_pred = hc.fit_predict(x)
mtp.scatter (x[y_pred == 0,0], x[y_pred == 0,1], s=100, c="red", label="Cluster1")
mtp.scatter (x[y_pred == 1,0], x[y_pred == 1,1], s=100, c="blue", label="Cluster2")
mtp.scatter (x[y_pred == 2,0], x[y_pred == 2,1], s=100, c="yellow", label="Cluster3")
mtp.scatter (x[y_pred == 3,0], x[y_pred == 3,1], s=100, c="pink", label="Cluster4")
mtp.scatter (x[y_pred == 4,0], x[y_pred == 4,1], s=100, c="cyan", label="Cluster5")
mtp.title ("Customer Cluster")
mtp.xlabel ("Annual Income k($)")
mtp.ylabel ("Spending score (1-100)")
mtp.legend()
mtp.show()

Slip 7........................................................

import numpy as np
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt 

x = np.array([1,2,3,4,5,6,7,8]).reshape(-1,1)
y = np.array([7,14,15,18,19,21,26,23])

model = LinearRegression()
model.fit(x,y)

b0 = model.intercept_
b1 = model.coef_[0]

print("b0 : " , b0 , "\tb1 : " , b1)

y_pred = model.predict(x)

plt.scatter(x,y)
plt.plot(x,y_pred)
plt.show()


Slip 8
........................................................

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs

data = make_blobs (n_samples=300, n_features=2, centers=5, cluster_std=1.8, random_state=101)
data[0].shape
data[1]

from sklearn.cluster import KMeans
kmeans = KMeans (n_clusters=5)
kmeans.fit(data[0])
kmeans.label_f, (ax1, ax2) = plt.subplots (1,2, sharey=True, figsize=(10,6))
ax1.set_title ('Original')
ax1.scatter (data[0][:,0], data[0][:,1], c=data[1], cmap='brg')
ax2.set_title ('K=Means')
ax2.scatter (data[0][:,0], data[0][:,1], c=kmeans.labels_, cmap='brg')
plt.show()

Slip9
.............................................................

from sklearn import datasets 
cancer = datasets.load_breast_cancer() 
print("Features: ", cancer.feature_names) 
print("Labels: ", cancer.target_names)  
cancer.data.shape 
print(cancer.data[0:5])  
print(cancer.target) 
from sklearn.model_selection import train_test_split 
X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3,random_state=109) 
from sklearn import svm 
clf = svm.SVC(kernel='linear')
clf.fit(X_train, y_train) 
y_pred = clf.predict(X_test) 
from sklearn import metrics 
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))


Slip 10
............................................................


Slip 11
..............................................................


Slip 12
................................................................

import pandas 
from sklearn import linear_model 
df = pandas.read_csv("cars.csv") 
X = df[['Weight', 'Volume']] 
y = df['CO2'] 
regr = linear_model.LinearRegression() 
regr.fit(X, y) 

predictedCO2 = regr.predict([[2300, 1300]]) 
print(predictedCO2)


Slip 13
................................................................

import pandas as pd 
data = pd.read_csv('StudentsPerformance.csv')
print("Shape of dataset : " , data.shape)
print("Top rows of dataset : \n" , data.head())

Slip 14
.............................................................



Slip 15
..........................................................

import pandas as pd 
from sklearn.tree import DecisionTreeClassifier

data = pd.read_csv('data.csv')

country_map = { 'USA' : 0 , 'UK' : 1 , 'N' : 2}
go_map = { 'YES' : 0 , 'NO' : 1}
data['Nationality'] = data['Nationality'].map(country_map)
data['Go'] = data['Go'].map(go_map)

x = data[['Age', 'Experience', 'Rank' ,'Nationality']]
y = data['Go'] 

clf = DecisionTreeClassifier()
clf.fit(x,y) 

temp = pd.DataFrame({'Age' : [40] , 'Experience' : [10] , 'Rank' : [7] , 'Nationality' : [0]})

pred = clf.predict(temp)
print(pred)

Slip 16
............................................................

import pandas as pd 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score , classification_report 

data = pd.read_csv('diabetes.csv')

x = data[['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']]
y = data['Outcome']

x_train , x_test , y_train , y_test = train_test_split(x,y,test_size = 0.2 , random_state = 42)


clf = DecisionTreeClassifier() 

clf.fit(x_train,y_train)

y_pred = clf.predict(x_test)

ac = accuracy_score(y_test,y_pred)
cr = classification_report(y_test,y_pred)

print("Ac : " , ac )
print("Cr : " , cr)

Slip 17
.......................................................

import pandas as pd
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

Stock_Market = {'Year':[2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016],
'Month': [12, 11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1],
'Interest_Rate': [2.75,2.5,2.5,2.5,2.5,2.5,2.5,2.25,2.25,2.25,2,2,2,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75],
'Unemployment_Rate':[5.3,5.3,5.3,5.3,5.4,5.6,5.5,5.5,5.5,5.6,5.7,5.9,6,5.9,5.8,6.1,6.2,6.1,6.1,6.1,5.9,6.2,6.2,6.1],
'Stock_Index_Price': [1464,1394,1357,1293,1256,1254,1234,1195,1159,1167,1130,1075,1047,965,943,958,971,949,884,866,876,822,704,719] }

df = pd.DataFrame(Stock_Market)

x = df[['Interest_Rate']]
y = df[['Stock_Index_Price']]

model = LinearRegression()

model.fit(x,y)

y_pred = model.predict(x)

plt.scatter(x,y , color = 'blue' , label = 'actual')
plt.xlabel('Interest Rate')
plt.ylabel('Stock_Index_Price')
plt.plot(x,y_pred , color = 'red'  , label = 'predicted')
plt.title('I vs S')
plt.legend()
plt.show()

Slip 18
.......................................................

import numpy as np 
import matplotlib.pyplot as plt  

def estimate_coef(x, y): 
    n = np.size(x)  
    m_x = np.mean(x) 
    m_y = np.mean(y)  
    SS_xy = np.sum(y*x) - n*m_y*m_x 
    SS_xx = np.sum(x*x) - n*m_x*m_x   
    b_1 = SS_xy / SS_xx 
    b_0 = m_y - b_1*m_x  
    return (b_0, b_1)  

def plot_regression_line(x, y, b): 
    plt.scatter(x, y, color="m", marker="o", s=30)   
    y_pred = b[0] + b[1]*x  
    plt.plot(x, y_pred, color="g") 
    plt.xlabel('x') 
    plt.ylabel('y') 
    plt.show() 

def main(): 
    x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13]) 
    y = np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12, 16, 18]) 
    b = estimate_coef(x, y) 
    print("Estimated coefficients:\nb_0 = {}\nb_1 = {}".format(b[0], b[1]))  
    plot_regression_line(x, y, b)  

if __name__ == "__main__":
    main()

or_ _ _ __ _ _ __ _ _ __ _ _ __ _ _ __ _ _ __ _ _ __ _ _ __ _ _ __ _ _ __ _ _ _

import numpy as np
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt 

x = np.array([1,2,3,4,5,6,7,8]).reshape(-1,1)
y = np.array([7,14,15,18,19,21,26,23])

model = LinearRegression()
model.fit(x,y)

b0 = model.intercept_
b1 = model.coef_[0]

print("b0 : " , b0 , "\tb1 : " , b1)

y_pred = model.predict(x)

plt.scatter(x,y)
plt.plot(x,y_pred)
plt.show()

Slip 19
.......................................................

import pandas 
from sklearn import linear_model 
df = pandas.read_csv("cars.csv") 
X = df[['Weight', 'Volume']] 
y = df['CO2'] 
regr = linear_model.LinearRegression() 
regr.fit(X.values, y) 

predictedCO2 = regr.predict([[2300, 1300]]) 
print(predictedCO2)

Slip 20
.....................................................

import numpy as nm 
import matplotlib.pyplot as mtp 
import pandas as pd 

dataset = pd.read_csv('Wholesale customers data.csv') 
dataset 
x = dataset.iloc[:, [3, 4]].values 
print(x) 

import scipy.cluster.hierarchy as shc 
dendro = shc.dendrogram(shc.linkage(x, method="ward")) 
mtp.title("Dendrogrma Plot") 
mtp.ylabel("Euclidean Distances") 
mtp.xlabel("Customers") 
mtp.show()
 
from sklearn.cluster import AgglomerativeClustering 
hc= AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward') 
y_pred= hc.fit_predict(x) 
mtp.scatter(x[y_pred == 0, 0], x[y_pred == 0, 1], s = 100, c = 'blue', label = 'Cluster 1') 
mtp.scatter(x[y_pred == 1, 0], x[y_pred == 1, 1], s = 100, c = 'green', label = 'Cluster 2') 
mtp.scatter(x[y_pred== 2, 0], x[y_pred == 2, 1], s = 100, c = 'red', label = 'Cluster 3')
mtp.scatter(x[y_pred == 3, 0], x[y_pred == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4') 
mtp.scatter(x[y_pred == 4, 0], x[y_pred == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5') 
mtp.title('Clusters of customers') 
mtp.xlabel('Milk') 
mtp.ylabel('Grocery') 
mtp.legend() 
mtp.show() 