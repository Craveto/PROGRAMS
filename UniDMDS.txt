DMDS_SOLN

*************************************************************************************************************

SLIP1:
Q1.Write a R program to add, multiply and divide two vectors of integer type. (Vector 
length should be minimum 4)[10 Marks] 

 x = c(10, 20, 30)
 y = c(20, 10, 40)
 print("Original Vectors:")
 print(x)
 print(y)
 print("Multiplication of two Vectors:")
 z = x * y
 print(z)
 print("Addition of two Vectors:")
 z = x + y
 print(z)
 print("Division of two Vectors:")
 z = x / y
 print(z)

Q2.Consider the student data set. It can be downloaded from: https://drive.google.com/openid=1oakZCv7g3mlmCSdv9J8kdSaqO5_6dIOw. 
Write a program in python to apply simple linear regression and find out mean absolute error, mean squared error and root mean squared error. [20 Marks]

import math  
import numpy as np
from sklearn.metrics import mean_absolute_error
actual = [2, 3, 5, 5, 9]
calculated = [3, 3, 8, 7, 6]
# Mean absolute error 
error = mean_absolute_error(actual, calculated)
print("Mean absolute error : " + str(error))
# Mean Squared Error
MSE = np.square(np.subtract(actual,calculated)).mean()
print("Mean squared error : " + str(MSE))
#Root mean square 
MSE = np.square(np.subtract(actual,calculated)).mean()   
RSME = math.sqrt(MSE)  
print("Root Mean squared error : " + str(RSME))

*****************************************************************************************************************************

SLIP2:

Q1. Write an R program to calculate the multiplication table using a function.
[10 Marks] 
number <- as.integer(readline(prompt = "Please Enter a Number for Table: "))
Disp_table=function(number) 
{ 
for( t in 1:10) 
{ 
print ( paste ( number, '*', t, '=', number * t)) 
Disp_table(number) 
} 
}

Q2.Write a python program to implement k-means algorithms on a synthetic 
dataset.[20 Marks]
 
import seaborn as sns 
import matplotlib.pyplot as plt 
from sklearn.datasets import make_blobs 
data = make_blobs(n_samples=300, n_features=2, centers=5, cluster_std=1.8,random_state=101) 
data[0].shape 
data[1] 
plt.scatter(data[0][:,0],data[0][:,1],c=data[1],cmap='brg')
from sklearn.cluster import KMeans 
kmeans = KMeans(n_clusters=5) 
kmeans.fit(data[0]) 
kmeans.cluster_centers_
kmeans.labels_f, (ax1, ax2) = plt.subplots(1, 2, sharey=True,figsize=(10,6))
ax1.set_title('K Means') 
ax1.scatter(data[0][:,0],data[0][:,1],c=kmeans.labels_,cmap='brg') 
ax2.set_title("Original") 
ax2.scatter(data[0][:,0],data[0][:,1],c=data[1],cmap='brg')

***************************************************************************************************

SLIP3:

Q1. Write a R program to reverse a number and also calculate the sum of digits of that 
number. [10 Marks] 
number=as.integer(readline(prompt("Enter a number: ")
Reverse_Sum = function(n) 
{ 
sum=0 
rev=0 
while(n>0) 
{ 
r = n%%10 
sum= sum+r; 
rev=rev*10+r 
n=n%/%10     # %/% is used for integer division
} 
print(paste("Sum of digit : ",sum))
print(paste("Reverse of number : ",rev)) 
} 
Reverse_Sum(n)

Q2. Consider the following observations/data. And apply simple linear regression and find out estimated coefficients b0 and b1
.( use numpy package) x=[0,1,2,3,4,5,6,7,8,9,11,13] y = ([1, 3, 2, 5, 7, 8, 8, 9, 10, 12,16, 18] [20 Marks] 
import numpy as np 
import matplotlib.pyplot as plt  
def estimate_coef(x, y): 
 n = np.size(x)  
 m_x = np.mean(x) 
 m_y = np.mean(y)  
 SS_xy = np.sum(y*x) - n*m_y*m_x 
 SS_xx = np.sum(x*x) - n*m_x*m_x   
 b_1 = SS_xy / SS_xx 
 b_0 = m_y - b_1*m_x  
 return (b_0, b_1)  
def plot_regression_line(x, y, b): 
 plt.scatter(x, y, color = "m", 
 marker = "o", s = 30)   
 y_pred = b[0] + b[1]*x  
 plt.plot(x, y_pred, color = "g") 
 plt.xlabel('x') 
 plt.ylabel('y') 
 plt.show() 
def main(): 
 x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9,11,13]) 
 y = np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12,16, 18]) 
 b = estimate_coef(x, y) 
 print("Estimated coefficients:\nb_0 = {} \ \nb_1 = {}".format(b[0], b[1]))  
 plot_regression_line(x, y, b)  
if __name__ == "__main__": 
 main()


*********************************************************************************************************************

SLIP4:

Q1. Write a R program to calculate the sum of two matrices of given size.[10Marks] 
x <- array(1:12, c(2, 3, 3))
# Getting the array representation
x  
colSums(x, dims = 1)
colSums(x, dims = 2)


Q2. Consider following dataset weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny','Rainy','Sunny',' Overcast','Overcast','Rainy'] 
temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild'] play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']. Use Naive Bayes algorithm to predict [0: Overcast, 2: Mild]tuple belongs to which  class whether to play the sports or not.
[20 Marks]
weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny', 'Rainy','Sunny','Overcast','Overcast','Rainy'] 
temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild'] 
play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No'] 
from sklearn import preprocessing 
le = preprocessing.LabelEncoder()  
wheather_encoded=le.fit_transform(weather) 
print (wheather_encoded) 
temp_encoded=le.fit_transform(temp) 
label=le.fit_transform(play) 
print ("Temp:",temp_encoded) 
print ("Play:",label) 
features=zip(wheather_encoded,temp_encoded) 
print (features) 
from sklearn.naive_bayes import GaussianNB  
model = GaussianNB() 
model.fit(features,label) 
predicted= model.predict([[0,2]]) # 0:Overcast, 2:Mild 
print("Predicted Value:", predicted)

*********************************************************************************************************************** 

SLIP5:

Q1. Write a R program to concatenate two given factors. [10 Marks]
f1 <- factor(sample(LETTERS, size=6, replace=TRUE)) 
f2 <- factor(sample(LETTERS, size=6, replace=TRUE)) 
print("Original factors:") 
print(f1) 
print(f2)
 f = factor(c(levels(f1)[f1], levels(f2)[f2])) 
print("After concatenate factor becomes:") 
print(f)

****************************************************************************************************************

SLIP6:
Q1. Write a R program to create a data frame using two given vectors and display the duplicate elements.[10 Marks] 
a = c(10,20,10,10,40,50,20,30)
b = c(10,30,10,20,0,50,30,30)
print("Original data frame:")
ab = data.frame(a,b)
print(ab)
print("Duplicate elements of the data frame:")
print(duplicated(ab))

Q2. Write a python program to implement hierarchical Agglomerative clustering algorithm. 
(Download Customer.csv dataset from github.com). [20 Marks] 
import pandas as pd
import matplotlib.pyplot as mtp
dataset = pd.read_csv('Mall_Customers.csv') 
x = dataset.iloc[:, [3, 4]].values 
import scipy.cluster.hierarchy as shc 
dendro = shc.dendrogram(shc.linkage(x, method="ward"))
mtp.title("Dendrogrma Plot") 
mtp.ylabel("Euclidean Distances") 
mtp.xlabel("Customers") 
mtp.show() 
from sklearn.cluster import AgglomerativeClustering 
hc= AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward') 
y_pred= hc.fit_predict(x)
mtp.scatter(x[y_pred == 0, 0], x[y_pred == 0, 1], s = 100, c = 'blue', label = 'Cluster 1') 
mtp.scatter(x[y_pred == 1, 0], x[y_pred == 1, 1], s = 100, c = 'green', label = 'Cluster 2') 
mtp.scatter(x[y_pred== 2, 0], x[y_pred == 2, 1], s = 100, c = 'red', label = 'Cluster 3') 
mtp.scatter(x[y_pred == 3, 0], x[y_pred == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4') 
mtp.scatter(x[y_pred == 4, 0], x[y_pred == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5') 
mtp.title('Clusters of customers') 
mtp.xlabel('Annual Income (k$)') 
mtp.ylabel('Spending Score (1-100)') 
mtp.legend() 
mtp.show()

*************************************************************************************************************************

SLIP7:

Q1. Write a R program to create a sequence of numbers from 20 to 50 and find the mean of numbers from 20 to 60 and sum of numbers from 51 to 91. [10 Marks] 
print("Sequence of numbers from 20 to 50:")
print(seq(20,50))
print("Mean of numbers from 20 to 60:")
print(mean(20:60))
print("Sum of numbers from 51 to 91:")
print(sum(51:91))

Q2. Consider the following observations/data. And apply simple linear regression and find out estimated coefficients b1 and b1 
Also analyse the performance of the model (Use sklearn package)  x=np.array ([1,2,3,4,5,6,7,8])   y=np.array([7,14,15,18,19,21,26,23]) 	
[20 Marks] 

import matplotlib.pyplot as plt 
from scipy import stats 
x = np.array([1,2,3,4,5,6,7,8]) 
y = np.array([7,14,15,18,19,21,26,23]) 
slope, intercept, r, p, std_err = stats.linregress(x, y) 
def myfunc(x): 
 return slope * x + intercept 
mymodel = list(map(myfunc, x)) 
plt.scatter(x, y) 
plt.plot(x, mymodel) 
plt.show() 

*******************************************************************************************

SLIP8:

Q1. Write a R program to get the first 10 Fibonacci numbers. [10 Marks] 
Fibonacci <- numeric(10) 
Fibonacci[1] <- Fibonacci[2] <- 1 
for (i in 3:10)
Fibonacci[i] <- Fibonacci[i - 2] + Fibonacci[i - 1] 
print("First 10 Fibonacci numbers:") 
print(Fibonacci)

Q2. Write a python program to implement k-means algorithm to build prediction model (Use 
Credit Card Dataset CC GENERAL.csv Download from kaggle.com)
#dataset --> https://www.kaggle.com/mlg-ulb/creditcardfraud/version/3 

import numpy as nm 
import matplotlib.pyplot as mtp 
import pandas as pd 
dataset = pd.read_csv('creditcard.csv') 
dataset 
x = dataset.iloc[:, [3, 4]].values 
print(x) 
from sklearn.cluster import KMeans 
wcss_list= [] 
for i in range(1, 11): 
kmeans = KMeans(n_clusters=i, init='k-means++', random_state= 42)
 kmeans.fit(x) 
wcss_list.append(kmeans.inertia_)
 mtp.plot(range(1, 11), wcss_list) 
mtp.title('The Elobw Method Graph') 
mtp.xlabel('Number of clusters(k)') 
mtp.ylabel('wcss_list')
 mtp.show() 
kmeans = KMeans(n_clusters=3, init='k-means++', random_state= 42) 
y_predict= kmeans.fit_predict(x)

*******************************************************************************************************************

SLIP9:
Q1. Write an R program to create a Data frames which contain details of 5 employees and display summary of the data. [10 Marks] 
Employees = data.frame(Name=c("Anastasia S","Dima R","Katherine S", "JAMES A","LAURA MARTIN"),
                      Gender=c("M","M","F","F","M"),
                      Age=c(23,22,25,26,32),
                      Designation=c("Clerk","Manager","Exective","CEO","ASSISTANT"),
                      SSN=c("123-34-2346","123-44-779","556-24-433","123-98-987","679-77-576")
                      )
print("Details of the employees:")                      
print(Employees)

Q2. Write a Python program to build an SVM model to Cancer dataset. The dataset is available in the scikit-learn library. 
Check the accuracy of model with precision and recall. 	[20 Marks] 

from sklearn import datasets 
cancer = datasets.load_breast_cancer() 
print("Features: ", cancer.feature_names) 
print("Labels: ", cancer.target_names)  
cancer.data.shape 
print(cancer.data[0:5])  
print(cancer.target) 
from sklearn.model_selection import train_test_split 
X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3,random_state=109) 
from sklearn import svm 
clf = svm.SVC(kernel='linear')
clf.fit(X_train, y_train) 
y_pred = clf.predict(X_test) 
from sklearn import metrics 
print("Accuracy:",metrics.accuracy_score(y_test, y_pred)) 

************************************************************************************************
 
SLIP10:

Q1. Write a R program to find the maximum and the minimum value of a givenvector [10 Marks] 
nums = c(10, 20, 30, 40, 50, 60) 
print('Original vector:') print(nums) 
print(paste("Maximum value of the said vector:",max(nums))) 
print(paste("Minimum value of the said vector:",min(nums)))

************************************************************************************************

slip11

Q1-Write a R program to find all elements of a given list that are not inanother given list.
A= list("x", "y", "z")
B= list("X", "Y", "Z", "x", "y", "z") [10 Marks]
l1 = list("x", "y", "z")
l2 = list("X", "Y", "Z", "x", "y", "z")
print("Original lists:")
print(l1)
print(l2)
print("All elements of l2 that are not in l1:")
setdiff(l2, l1)

*************************************************************************************************

slip12

Q1-Write a R program to create a Dataframes which contain details of 5employees and
display the details.
Employee contain (empno,empname,gender,age,designation)
[10 Marks]
Employees = data.frame(Name=c("Anastasia S","Dima R","Katherine S", "JAMES A","LAURA MARTIN"),
                      Gender=c("M","M","F","F","M"),
                      Age=c(23,22,25,26,32),
                      Designation=c("Clerk","Manager","Exective","CEO","ASSISTANT"),
                      SSN=c("123-34-2346","123-44-779","556-24-433","123-98-987","679-77-576")
                      )
print("Details of the employees:")                      
print(Employees)
Q2-Write a python program to implement multiple Linear Regression modelfor a car dataset.
Dataset can be downloaded from:
https://www.w3schools.com/python/python_ml_multiple_regression.asp [20 Marks]
import pandas as pd
from sklearn import linear_model 
df = pd.read_csv("cars.csv") 
X = df[['Weight', 'Volume']] 
y = df['CO2'] 
regr = linear_model.LinearRegression() 
regr.fit(X, y) 
predictedCO2 = regr.predict([[2300, 1300]]) 
print(predictedCO2) 

**********************************************************************************************

slip13

Q1- Draw a pie chart using R programming for the following datadistribution:
Digits on Dice                                     1 2 3 4 5 6
Frequency of getting each number 7 2 6 3 4 8 [10 Marks]
# Create data for the graph.
DigitsonDice <- c(1,2,3,4,5,6)
Frequency<- c(7, 2, 6 ,3 ,4, 8)
# Plot the chart.
pie(DigitsonDice,Frequency)
# Save the file.
dev.off()

***********************************************************************************************

slip14

Q1-Q1. Write a script in R to create a list of employees (name) and perform thefollowing:
a. Display names of employees in the list.
b. Add an employee at the end of the list
c. Remove the third element of the list. [10 Marks]
> list_data <- list("Ram Sharma","Sham Varma","Raj Jadhav", "Ved Sharma") 
#display list 
> print(list_data) 
#create new employee 
new_Emp <-"Kavya Anjali" 
#Add new employee at the end 
list_data <-append(list_data,new_Emp) 
#remove 3 employee 
list_data[3] <- NULL 
print(list_data)

************************************************************************************************ 

slip15

Q1.Write a R program to add, multiply and divide two vectors of integer type.(vector length
should be minimum 4) [10 Marks]
x = c(10, 20, 30)
 y = c(20, 10, 40)
 print("Original Vectors:")
 print(x)
 print(y)
 print("addition of two Vectors:")
 z = x + y
 print(z)
 print("multiply of two Vectors:")
 z = x * y
 print(z)
 print("division of two Vectors:")
 z = x / y
 print(z)

Q2. Write a Python program build Decision Tree Classifier forshows.csvfrom pandas and 
predict class label for show starring a 40 years old American comedian, with 10 
years of experience, and a comedy ranking of 7? Create a csv file as shown in
https://www.w3schools.com/python/python_ml_decision_tree.asp
[20 Marks]
import pandas 
from sklearn import tree 
import pydotplus 
from sklearn.tree import DecisionTreeClassifier 
import matplotlib.pyplot as plt 
import matplotlib.image as pltimg 
df = pandas.read_csv("c:\shows.csv") 
d = {'UK': 0, 'USA': 1, 'N': 2} 
df['Nationality'] = df['Nationality'].map(d) 
d = {'YES': 1, 'NO': 0} 
df['Go'] = df['Go'].map(d) 
features = ['Age', 'Experience', 'Rank', 'Nationality'] 
X = df[features] 
y = df['Go'] 
dtree = DecisionTreeClassifier()
dtree = dtree.fit(X, y) 
data = tree.export_graphviz(dtree, out_file=None, feature_names=features) 
graph = pydotplus.graph_from_dot_data(data) 
graph.write_png('mydecisiontree.png') 
img=pltimg.imread('mydecisiontree.png') 
imgplot = plt.imshow(img) 
plt.show() 

****************************************************************************************************************

slip16

Q1. Write a R program to create a simple bar plot of given data
Year Export Import
2001 26 35
2002 32 40
2003 35 50
[10 Marks]
# Create the input vectors.
colors = c("green","orange")
year <- c(2001,2002,2003)
regions <- c("import","Export")
# Create the matrix of the values.
Values <- matrix(c(26,32,35,35,40,50), nrow = 2, ncol = 3, byrow = TRUE)
# Create the bar chart
barplot(Values, main = "import/export", names.arg = year, xlab = "year", ylab = "import/export", col = colors)
# Add the legend to the chart
legend("topleft", regions, cex = 1.3, fill = colors)
# Save the file
dev.off()

*****************************************************************************************************************

slip17

Q1. Write a R program to get the first 20 Fibonacci numbers.
[10 Marks]
Fibonacci <- numeric(20)
Fibonacci[1] <- Fibonacci[2] <- 1
for (i in 3:20) Fibonacci[i] <- Fibonacci[i - 2] + Fibonacci[i - 1]
print("First 20 Fibonacci numbers:")
print(Fibonacci)

Q2. Write a python programme to implement multiple linear regression modelfor stock market
data frame as follows:
Stock_Market = {'Year':[2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2016,2016,20,16,2016,2016,2016,2016,2016,2016,2016,2016,2016],
'Month': [12, 11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1],
'Interest_Rate': [2.75,2.5,2.5,2.5,2.5,2.5,2.5,2.25,2.25,2.25,2,2,2,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75],
'Unemployment_Rate':[5.3,5.3,5.3,5.3,5.4,5.6,5.5,5.5,5.5,5.6,5.7,5.9,6,5.9,5.8,6.1,6.2,6.1,6.1,6.1,5.9,6.2,6.2,6.1],
'Stock_Index_Price': [1464,1394,1357,1293,1256,1254,1234,1195,1159,1167,1130,1075,1047,965,943,958,971,949,884,866,876,822,704,719] }
And draw a graph of stock market price verses interest rate.
[20 Marks]
import pandas as pd 
import matplotlib.pyplot as plt 
 Stock_Market = {'Year': 
[2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016], 
 'Month': [12, 11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1], 
 'Interest_Rate': 
[2.75,2.5,2.5,2.5,2.5,2.5,2.5,2.25,2.25,2.25,2,2,2,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75], 
 'Unemployment_Rate': 
[5.3,5.3,5.3,5.3,5.4,5.6,5.5,5.5,5.5,5.6,5.7,5.9,6,5.9,5.8,6.1,6.2,6.1,6.1,6.1,5.9,6.2,6.2,6.1], 
 'Stock_Index_Price': 
[1464,1394,1357,1293,1256,1254,1234,1195,1159,1167,1130,1075,1047,965,943,958,971
,949,884,866,876,822,704,719] 
 } 
df = pd.DataFrame(Stock_Market,columns=['Year','Month','Interest_Rate','Unemployment_Rate','Stock_Index_Price'])  
plt.scatter(df['Interest_Rate'], df['Stock_Index_Price'], color='red') 
plt.title('Stock Index Price Vs Interest Rate', fontsize=14) 
plt.xlabel('Interest Rate', fontsize=14) 
plt.ylabel('Stock Index Price', fontsize=14) 
plt.grid(True) 
plt.show()

*******************************************************************************************************************

slip18

Q1. Write a R program to find the maximum and the minimum value of a given vector [10Marks]
nums = c(10, 20, 30, 40, 50, 60)
print('Original vector:')
print(nums)   
print(paste("Maximum value of the said vector:",max(nums)))
print(paste("Minimum value of the said vector:",min(nums)))

Q2. Consider the following observations/data. And apply simple linear regression and find out
estimated coefficients b1 and b1 Also analyse theperformance of the model
(Use sklearn package)
import numpy as np 
import matplotlib.pyplot as plt  
def estimate_coef(x, y): 
 n = np.size(x)  
 m_x = np.mean(x) 
 m_y = np.mean(y)  
 SS_xy = np.sum(y*x) - n*m_y*m_x 
 SS_xx = np.sum(x*x) - n*m_x*m_x   
 b_1 = SS_xy / SS_xx 
 b_0 = m_y - b_1*m_x  
 return (b_0, b_1)  
def plot_regression_line(x, y, b): 
 plt.scatter(x, y, color = "m", 
 marker = "o", s = 30)   
 y_pred = b[0] + b[1]*x  
 plt.plot(x, y_pred, color = "g") 
 plt.xlabel('x') 
 plt.ylabel('y') 
 plt.show() 
def main(): 
 x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9,11,13]) 
 y = np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12,16, 18]) 
 b = estimate_coef(x, y) 
 print("Estimated coefficients:\nb_0 = {} \ \nb_1 = {}".format(b[0], b[1]))  
 plot_regression_line(x, y, b)  
if __name__ == "__main__": 
 main()

*************************************************************************************************************************** 

slip19
Q1. Write aR program to create a Dataframes which contain details of 5 Students and display the
details.Students contain (Rollno,Studname,Address,Marks) [10 Marks]
Employees = data.frame(Name=c("Anastasia S","Dima R","Katherine S", "JAMES A","LAURA MARTIN"),
                      Gender=c("M","M","F","F","M"),
                      Age=c(23,22,25,26,32),
                      Designation=c("Clerk","Manager","Exective","CEO","ASSISTANT"),
                      SSN=c("123-34-2346","123-44-779","556-24-433","123-98-987","679-77-576")
                      )
print("Summary of the data:")                      
print(summary(Employees))

Q2. Write a python program to implement multiple Linear Regression modelfor a car dataset.
Dataset can be downloaded from:
https://www.w3schools.com/python/python_ml_multiple_regression.asp
[20 Marks]
import pandas 
from sklearn import linear_model 
df = pandas.read_csv("carsdata.csv") 
X = df[['Weight', 'Volume']] 
y = df['CO2'] 
regr = linear_model.LinearRegression() 
regr.fit(X, y) 
#predict the CO2 emission of a car where the weight is 2300kg, and the volume is 1300cm3: 
predictedCO2 = regr.predict([[2300, 1300]]) 
print(predictedCO2) 

****************************************************************************************************************************

slip20
Q1. Write a R program to create a data frame from four given vectors.
[10 Marks]
 name = c('Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas')
score = c(12.5, 9, 16.5, 12, 9, 20, 14.5, 13.5, 8, 19)
attempts = c(1, 3, 2, 3, 2, 3, 1, 1, 2, 1)
qualify = c('yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes')
print("Original data frame:")
print(name)
print(score)
print(attempts)
print(qualify)
df = data.frame(name, score, attempts, qualify)  
print(df)

Q2. Write a python program to implement hierarchical Agglomerative clustering algorithm.
(Download Customer.csv dataset from github.com).
[20 Marks]      ass6
import numpy as nm 
import matplotlib.pyplot as mtp 
import pandas as pd 
dataset = pd.read_csv('Wholesale customers data.csv') 
dataset 
x = dataset.iloc[:, [3, 4]].values 
print(x) 
import scipy.cluster.hierarchy as shc 
dendro = shc.dendrogram(shc.linkage(x, method="ward")) 
mtp.title("Dendrogrma Plot") 
mtp.ylabel("Euclidean Distances") 
mtp.xlabel("Customers") 
mtp.show() 
from sklearn.cluster import AgglomerativeClustering 
hc= AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward') 
y_pred= hc.fit_predict(x) 
mtp.scatter(x[y_pred == 0, 0], x[y_pred == 0, 1], s = 100, c = 'blue', label = 'Cluster 1') 
mtp.scatter(x[y_pred == 1, 0], x[y_pred == 1, 1], s = 100, c = 'green', label = 'Cluster 2') 
mtp.scatter(x[y_pred== 2, 0], x[y_pred == 2, 1], s = 100, c = 'red', label = 'Cluster 3')
mtp.scatter(x[y_pred == 3, 0], x[y_pred == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4') 
mtp.scatter(x[y_pred == 4, 0], x[y_pred == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5') 
mtp.title('Clusters of customers') 
mtp.xlabel('Milk') 
mtp.ylabel('Grocery') 
mtp.legend() 
mtp.show() 
===============================================================================================not running programs
slip5:
Q2. Write a Python program build Decision Tree Classifier using Scikit-learn package for diabetes data set 
(download database from https://www.kaggle.com/uciml/pima-indians-diabetes-database) [20 Marks] 
import pandas as pd 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.model_selection import train_test_split 
from sklearn import metrics 
pima = pd.read_csv("diabetes.csv") 
pima.head() 
import seaborn as sns 
corr = pima.corr() 
ax = sns.heatmap(corr,vmin=-1, vmax=1, center=0,cmap=sns.diverging_palette(20, 220, n=200), square=True ) 
ax.set_xticklabels( ax.get_xticklabels(), rotation=45, horizontalalignment='right' ); 
feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age', 'Glucose', 'BloodPressure', 'DiabetesPedigreeFunction'] 
x = pima[feature_cols] 
y = pima.Outcome 
X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.3, random_state=1)  
classifier = DecisionTreeClassifier() 
classifier = classifier.fit(X_train, Y_train) 
y_pred = classifier.predict(X_test) 
print(y_pred) 
from sklearn.metrics import confusion_matrix 
confusion_matrix(Y_test, y_pred) 
print(confusion_matrix(Y_test, y_pred)) 
print("Accuracy:", metrics.accuracy_score(Y_test,y_pred)) 
from six import StringIO 
from IPython.display import Image 
from sklearn.tree import export_graphviz 
import pydotplus 
dot_data = StringIO() 
export_graphviz(classifier, out_file=dot_data, filled=True, rounded=True, special_characters=True, feature_names = feature_cols,class_names=['0','1']) 
graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) 
graph.write_png('diabetes.png') 
Image(graph.create_png())

slip10:
Q2. Write a Python Program to read the dataset (“Iris.csv”). dataset download from 
(https://archive.ics.uci.edu/ml/datasets/iris) and apply Apriori algorithm. 	[20 Marks] 
"cells": [ 
 { 
 "cell_type": "markdown", 
 "id": "b58228cb", 
 "metadata": {}, 
 "source": [ 
 "# SET - A\n", 
 "\n", 
 "### 1) Write a code to read the dataset (“Iris.csv”). dataset download from 
(https://archive.ics.uci.edu/ml/datasets/iris) and apply Apriori algorithm." 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": 1, 
 "id": "31f28134", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "import numpy as np\n", 
 "import matplotlib.pyplot as plt\n", 
 "import pandas as pd\n", 
 "from apyori import apriori" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "91ef7af6", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "store_data=pd.read_csv('iris.csv',header=None)" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "cd4c9ed9", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "store_data.head()\n" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "88d01808", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "records = []\n", 
 "for i in range(0,300):\n", 
 " records.append([str(store_data.values[i,j]) for j in range(0,20)])\n" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "ba30cca3", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 
"association_rules=apriori(records,min_support=0.0045,min_confidence=0.2,min_lift=3,min
_length=2)\n", 
 "association_results=list(association_rules)\n" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "8ab0102a", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "print(len(association_results))\n" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "daa923d5", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "print(association_results[0])\n" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "4f9ceaad", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "for item in association_results:\n", 
 " pair = item[0]\n", 
 " items = [x for x in pair]\n", 
 " print(\"Rule:\"+items[0]+\"->\"+items[1])\n", 
 " \n", 
 " print(\"Support:\"+str(item[1]))\n", 
 "\n", 
 " print(\"Confidence:\"+str(item[2][0][2]))\n", 
 " print(\"Lift:\"+str(item[2][0][3]))\n", 
 " print(\"========================================\")" 
 ] 
 } 
 ], 
 "metadata": { 
 "kernelspec": { 
 "display_name": "Python 3 (ipykernel)", 
 "language": "python", 
 "name": "python3" 
 }, 
 "language_info": { 
 "codemirror_mode": { 
 "name": "ipython", 
 "version": 3 
 }, 
 "file_extension": ".py", 
 "mimetype": "text/x-python", 
 "name": "python", 
 "nbconvert_exporter": "python", 
 "pygments_lexer": "ipython3", 
 "version": "3.7.9" 
 } 
 }, 
 "nbformat": 4, 
 "nbformat_minor": 5 
}
slip 11:
Q2-Write a python program to implement hierarchical clustering algorithm.(Download
Wholesale customers data dataset from github.com). [20 Marks]     ass6
import numpy as nm 
import matplotlib.pyplot as mtp 
import pandas as pd 
dataset = pd.read_csv('Wholesale customers data.csv') 
dataset 
x = dataset.iloc[:, [3, 4]].values 
print(x) 
import scipy.cluster.hierarchy as shc 
dendro = shc.dendrogram(shc.linkage(x, method="ward")) 
mtp.title("Dendrogrma Plot") 
mtp.ylabel("Euclidean Distances") 
mtp.xlabel("Customers") 
mtp.show() 
from sklearn.cluster import AgglomerativeClustering 
hc= AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward') 
y_pred= hc.fit_predict(x) 
mtp.scatter(x[y_pred == 0, 0], x[y_pred == 0, 1], s = 100, c = 'blue', label = 'Cluster 1') 
mtp.scatter(x[y_pred == 1, 0], x[y_pred == 1, 1], s = 100, c = 'green', label = 'Cluster 2') 
mtp.scatter(x[y_pred== 2, 0], x[y_pred == 2, 1], s = 100, c = 'red', label = 'Cluster 3')
mtp.scatter(x[y_pred == 3, 0], x[y_pred == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4') 
mtp.scatter(x[y_pred == 4, 0], x[y_pred == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5') 
mtp.title('Clusters of customers') 
mtp.xlabel('Milk') 
mtp.ylabel('Grocery') 
mtp.legend() 
mtp.show() 

slip13:
Q2-Write a Python program to read “StudentsPerformance.csv” file. Solvefollowing:
- To display the shape of dataset.
- To display the top rows of the dataset with their columns.Note: Download
dataset from following link :
(https://www.kaggle.com/spscientist/students-performance-inexams?
select=StudentsPerformance.csv) [20 Marks]
{ 
 "nbformat": 4, 
 "nbformat_minor": 0, 
 "metadata": { 
 "colab": { 
 "name": "Data Mining Assignment-3 SET-B-1.ipynb", 
 "provenance": [] 
 }, 
 "kernelspec": { 
 "name": "python3", 
 "display_name": "Python 3" 
 }, 
 "language_info": { 
 "name": "python" 
 } 
 }, 
 "cells": [ 
 { 
 "cell_type": "markdown", 
 "source": [ 
 "### SET-B\n", 
 "\n", 
 "1) Write a Python program to read \"StudentsPerformance.csv\" file. solve the 
following :\n", 
 "- To display the shape of dataset.\n", 
 "- To display the top rows of the dataset with their columns.\n", 
 "- To display the number of rows randomly.\n", 
 "- To display the number of columns and names of the columns.\n", 
 "- Note : Download dataset from following link:\n", 
 "(https://www.kaggle.com/spscientist/students-performance-inexams?select=StudentsPerformance.csv)" 
 ], 
 "metadata": { 
 "id": "0hhW5uEs_wK2" 
 } 
 }, 
 { 
 "cell_type": "code", 
 "source": [ 
 "# Import required libraries\n", 
 "import numpy as np\n", 
 "import matplotlib.pyplot as plt\n",
 "import pandas as pd\n" 
 ], 
 "metadata": { 
 "id": "W61H7Yo7E_sP" 
 }, 
 "execution_count": 2, 
 "outputs": [] 
 }, 
 { 
 "cell_type": "code", 
 "source": [ 
 "# Read the downloaded dataset\n", 
 "store_data=pd.read_csv('StudentsPerformance.csv',header=None)" 
 ], 
 "metadata": { 
 "id": "uC2jGgIFFVa3" 
 }, 
 "execution_count": null, 
 "outputs": [] 
 }, 
 { 
 "cell_type": "code", 
 "source": [ 
 "# To display the shape of dataset. (By Using shape method)\n", 
 "store_data.shape" 
 ], 
 "metadata": { 
 "id": "wU6-JdtCF3ar" 
 }, 
 "execution_count": null, 
 "outputs": [] 
 }, 
 { 
 "cell_type": "code", 
 "source": [ 
 "# To display the top rows of the dataset with their columns.(By using head method\n", 
 "store_data.head()" 
 ], 
 "metadata": { 
 "id": "xHtDSrSsGT2v" 
 }, 
 "execution_count": null, 
 "outputs": [] 
 }, 
 { 
 "cell_type": "code", 
 "source": [ 
 "# To display the number of rows randomly.(By using sample method)\n", 
 "store_data.sample(10)"
  ], 
 "metadata": { 
 "id": "2Gwsi4oTG9QN" 
 }, 
 "execution_count": null, 
 "outputs": [] 
 }, 
 { 
 "cell_type": "code", 
 "source": [ 
 "# To display the number of columns and names of the columns. (By using columns 
method)\n", 
 "store_data.columns()" 
 ], 
 "metadata": { 
 "id": "ZdXc3aoUHO80" 
 }, 
 "execution_count": null, 
 "outputs": [] 
 } 
 ] 
} 
slip14:
Q2-Write a Python Programme to apply Apriori algorithm on Groceries dataset. Dataset
can be downloaded from
(https://github.com/amankharwal/Websitedata/blob/master/Groceries
_dataset.csv).
Also display support and confidence for each rule.
[20 Marks]
{ 
 "nbformat": 4, 
 "nbformat_minor": 0, 
 "metadata": { 
 "colab": { 
 "name": "Data Mining Assignment-3 SET-B-2.ipynb", 
 "provenance": [] 
 }, 
 "kernelspec": { 
 "name": "python3", 
 "display_name": "Python 3" 
 }, 
 "language_info": { 
 "name": "python" 
 } 
 }, 
 "cells": [ 
 { 
 "cell_type": "markdown", 
 "source": [ 
 "SET - B\n", 
"\n", 
 "2) Write a code to read the dataset (“groceries.csv”). dataset download from 
(https://www.kaggle.com/irfanasrullah/groceries) and apply Apriori algorithm with 
min_support=0.0040, min_support=0.2, min_lift=3, min_length=2." 
 ], 
 "metadata": { 
 "id": "pVfZJLMAvGIJ" 
 } 
 }, 
 { 
 "cell_type": "code", 
 "source": [ 
 "import numpy as np\n", 
 "import matplotlib.pyplot as plt\n", 
 "import pandas as pd\n", 
 "from apyori import apriori" 
 ], 
 "metadata": { 
 "id": "7KuTYHw1vNJf" 
 }, 
 "execution_count": null, 
 "outputs": [] 
 }, 
 { 
 "cell_type": "code", 
 "source": [ 
 "store_data=pd.read_csv('groceries.csv',header=None)" 
 ], 
 "metadata": { 
 "id": "QvlmFxy16yLg" 
 }, 
 "execution_count": null, 
 "outputs": [] 
 }, 
 { 
 "cell_type": "code", 
 "source": [ 
 "store_data.head()" 
 ], 
 "metadata": { 
 "id": "wwm9lexq-pdY" 
 }, 
 "execution_count": null, 
 "outputs": [] 
 }, 
 { 
 "cell_type": "code", 
 "source": [ 
 "records = []\n",
 "for i in range(0,300):\n", 
 " records.append([str(store_data.values[i,j]) for j in range(0,20)])\n" 
 ], 
 "metadata": { 
 "id": "p4_M413V-tkY" 
 }, 
 "execution_count": null, 
 "outputs": [] 
 }, 
 { 
 "cell_type": "code", 
 "source": [ 
 
"association_rules=apriori(records,min_support=0.0040,min_confidence=0.2,min_lift=3,min
_length=2)\n", 
 "association_results=list(association_rules)\n" 
 ], 
 "metadata": { 
 "id": "7ZTOd9jQ-z5F" 
 }, 
 "execution_count": null, 
 "outputs": [] 
 }, 
 { 
 "cell_type": "code", 
 "source": [ 
 "print(len(association_results))" 
 ], 
 "metadata": { 
 "id": "LYXHcNQs-_Cj" 
 }, 
 "execution_count": null, 
 "outputs": [] 
 }, 
 { 
 "cell_type": "code", 
 "source": [ 
 "print(association_results[0])" 
 ], 
 "metadata": { 
 "id": "1gmQcNZk_Ekl" 
 }, 
 "execution_count": null, 
 "outputs": [] 
 }, 
 { 
 "cell_type": "code", 
 "source": [ 
 "for item in association_results:\n",
 " pair = item[0]\n", 
 " items = [x for x in pair]\n", 
 " print(\"Rule:\"+items[0]+\"->\"+items[1])\n", " \n", 
 " print(\"Support:\"+str(item[1]))\n", "\n", 
 " print(\"Confidence:\"+str(item[2][0][2]))\n", " 
print(\"Lift:\"+str(item[2][0][3]))\n", 
 " print(\"========================================\")" 
 ], 
 "metadata": { 
 "id": "mNizziCV_Jp-" 
 }, 
 "execution_count": null, 
 "outputs": [] 
 } 
 ] 
} 

slip16:
Q2. Write a Python program build Decision Tree Classifier using Scikit-learnpackage for 
diabetes data set (download database from https://www.kaggle.com/uciml/pima-indiansdiabetes-database)
[20 Marks]
import pandas as pd 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.model_selection import train_test_split 
from sklearn import metrics 
pima = pd.read_csv("C:\\Users\\Asus\\Desktop\\DMDWLAb Book Material\diabetes.csv") 
pima.head() 
import seaborn as sns 
corr = pima.corr() 
ax = sns.heatmap( 
 corr, 
 vmin=-1, vmax=1, center=0, 
cmap=sns.diverging_palette(20, 220, n=200), 
 square=True 
) 
ax.set_xticklabels( 
 ax.get_xticklabels(), 
 rotation=45, 
 horizontalalignment='right' 
); 
# feature selection 
feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age', 'Glucose', 'BloodPressure', 
'DiabetesPedigreeFunction'] 
x = pima[feature_cols] 
y = pima.Outcome 
# split data 
X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.3, 
random_state=1) 
# build model 
classifier = DecisionTreeClassifier() 
classifier = classifier.fit(X_train, Y_train) 
# predict 
y_pred = classifier.predict(X_test) 
print(y_pred) 
from sklearn.metrics import confusion_matrix 
confusion_matrix(Y_test, y_pred) 
print(confusion_matrix(Y_test, y_pred)) 
# accuracy 
print("Accuracy:", metrics.accuracy_score(Y_test,y_pred)) 
from six import StringIO 
from IPython.display import Image 
from sklearn.tree import export_graphviz 
import pydotplus 
dot_data = StringIO() 
export_graphviz(classifier, out_file=dot_data, 
 filled=True, rounded=True, 
 special_characters=True, feature_names = 
feature_cols,class_names=['0','1']) 
graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) 
graph.write_png('diabetes.png') 
Image(graph.create_png()) 



